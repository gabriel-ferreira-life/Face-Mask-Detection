{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gdown\n",
    "import json\n",
    "import sys\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "pd.set_option('display.max_columns', 20)\n",
    "\n",
    "from ultralytics import YOLO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_config(self):\n",
    "        # Get the absolute path to the current script directory\n",
    "        script_dir = os.path.dirname(os.path.abspath(__file__))\n",
    "\n",
    "        # Move one level up to the parent directory\n",
    "        parent_dir = os.path.dirname(script_dir)\n",
    "\n",
    "        # Construct the path to the config.json file in the parent directory's config folder\n",
    "        config_path = os.path.join(parent_dir, 'config', 'config.json')\n",
    "\n",
    "        # Load the config file\n",
    "        with open(config_path, 'r') as f:\n",
    "            config = json.load(f)\n",
    "        \n",
    "        return config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cwd = os.getcwd()\n",
    "# parent_dir = os.path.dirname(cwd)\n",
    "\n",
    "# # Construct the path to the config.json file in the parent directory's config folder\n",
    "# config_path = os.path.join(parent_dir, 'config.json')\n",
    "\n",
    "# Load the config file\n",
    "with open('config.json', 'r') as f:\n",
    "    config = json.load(f)\n",
    "\n",
    "file_id = config['file_id']\n",
    "url = config['url'].replace(\"file_id\", file_id)\n",
    "model_output_path = config['model_output_path']\n",
    "model_output_file = config['model_output_file']\n",
    "model_loc = os.path.join(model_output_path, model_output_file)\n",
    "inference_files_path = config['inference_files_path']\n",
    "prediction_files_path = config['prediction_files_path']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading model from cloud...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'../Model/yolo11n.pt'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # Download model\n",
    "# print(\"Downloading model from cloud...\")\n",
    "# if not os.path.exists(model_output_path):\n",
    "#     os.makedirs(model_output_path)\n",
    "# gdown.download(url, model_loc, quiet=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/gabrielvictorgomesferreira/artificial_intelligence/isu_classes/projects/Face-Mask-Detection/Data/Inference_Files'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Resolve absolute paths\n",
    "inference_files_path = os.path.abspath(inference_files_path)\n",
    "prediction_files_path = os.path.abspath(prediction_files_path)\n",
    "prediction_files_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.3.37 ðŸš€ Python-3.11.0 torch-2.2.2 CPU (Intel Core(TM) i5-8257U 1.40GHz)\n",
      "YOLO11n summary (fused): 238 layers, 2,582,737 parameters, 0 gradients, 6.3 GFLOPs\n",
      "\n",
      "2024-11-26 01:12:12.381 python[4866:3626087] +[IMKClient subclass]: chose IMKClient_Modern\n",
      "2024-11-26 01:12:12.381 python[4866:3626087] +[IMKInputSession subclass]: chose IMKInputSession_Modern\n",
      "image 1/5 /Users/gabrielvictorgomesferreira/artificial_intelligence/isu_classes/projects/Face-Mask-Detection/Data/Inference_Files/maksssksksss9.png: 640x448 1 without_mask, 1 mask_weared_incorrect, 99.0ms\n",
      "image 2/5 /Users/gabrielvictorgomesferreira/artificial_intelligence/isu_classes/projects/Face-Mask-Detection/Data/Inference_Files/maksssksksss90.png: 448x640 1 without_mask, 10 with_masks, 100.6ms\n",
      "image 3/5 /Users/gabrielvictorgomesferreira/artificial_intelligence/isu_classes/projects/Face-Mask-Detection/Data/Inference_Files/maksssksksss91.png: 384x640 5 with_masks, 102.6ms\n",
      "image 4/5 /Users/gabrielvictorgomesferreira/artificial_intelligence/isu_classes/projects/Face-Mask-Detection/Data/Inference_Files/maksssksksss93.png: 448x640 10 with_masks, 85.0ms\n",
      "image 5/5 /Users/gabrielvictorgomesferreira/artificial_intelligence/isu_classes/projects/Face-Mask-Detection/Data/Inference_Files/maksssksksss94.png: 384x640 2 without_masks, 5 with_masks, 1 mask_weared_incorrect, 88.9ms\n",
      "Speed: 3.6ms preprocess, 95.2ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1m../Data/Prediction_Files\u001b[0m\n",
      "ðŸ’¡ Learn more at https://docs.ultralytics.com/modes/predict\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "!yolo task=detect mode=predict \\\n",
    "    model={model_loc} \\\n",
    "    source={inference_files_path} \\\n",
    "    project=../Data \\\n",
    "    name=Prediction_Files \\\n",
    "    exist_ok=True \\\n",
    "    show=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/gabrielvictorgomesferreira/artificial_intelligence/isu_classes/projects/Face-Mask-Detection/Data/Inference_Files/maksssksksss94.png\n",
      "\n",
      "image 1/1 /Users/gabrielvictorgomesferreira/artificial_intelligence/isu_classes/projects/Face-Mask-Detection/Data/Inference_Files/maksssksksss94.png: 384x640 2 without_masks, 5 with_masks, 1 mask_weared_incorrect, 93.9ms\n",
      "Speed: 3.5ms preprocess, 93.9ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1m/Users/gabrielvictorgomesferreira/runs/detect/predict4\u001b[0m\n",
      "/Users/gabrielvictorgomesferreira/artificial_intelligence/isu_classes/projects/Face-Mask-Detection/Data/Inference_Files/maksssksksss93.png\n",
      "\n",
      "image 1/1 /Users/gabrielvictorgomesferreira/artificial_intelligence/isu_classes/projects/Face-Mask-Detection/Data/Inference_Files/maksssksksss93.png: 448x640 10 with_masks, 96.5ms\n",
      "Speed: 3.1ms preprocess, 96.5ms inference, 0.7ms postprocess per image at shape (1, 3, 448, 640)\n",
      "Results saved to \u001b[1m/Users/gabrielvictorgomesferreira/runs/detect/predict4\u001b[0m\n",
      "/Users/gabrielvictorgomesferreira/artificial_intelligence/isu_classes/projects/Face-Mask-Detection/Data/Inference_Files/maksssksksss91.png\n",
      "\n",
      "image 1/1 /Users/gabrielvictorgomesferreira/artificial_intelligence/isu_classes/projects/Face-Mask-Detection/Data/Inference_Files/maksssksksss91.png: 384x640 5 with_masks, 77.2ms\n",
      "Speed: 1.6ms preprocess, 77.2ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1m/Users/gabrielvictorgomesferreira/runs/detect/predict4\u001b[0m\n",
      "/Users/gabrielvictorgomesferreira/artificial_intelligence/isu_classes/projects/Face-Mask-Detection/Data/Inference_Files/maksssksksss90.png\n",
      "\n",
      "image 1/1 /Users/gabrielvictorgomesferreira/artificial_intelligence/isu_classes/projects/Face-Mask-Detection/Data/Inference_Files/maksssksksss90.png: 448x640 1 without_mask, 10 with_masks, 108.5ms\n",
      "Speed: 2.2ms preprocess, 108.5ms inference, 0.6ms postprocess per image at shape (1, 3, 448, 640)\n",
      "Results saved to \u001b[1m/Users/gabrielvictorgomesferreira/runs/detect/predict4\u001b[0m\n",
      "/Users/gabrielvictorgomesferreira/artificial_intelligence/isu_classes/projects/Face-Mask-Detection/Data/Inference_Files/maksssksksss9.png\n",
      "\n",
      "image 1/1 /Users/gabrielvictorgomesferreira/artificial_intelligence/isu_classes/projects/Face-Mask-Detection/Data/Inference_Files/maksssksksss9.png: 640x448 1 without_mask, 1 mask_weared_incorrect, 97.0ms\n",
      "Speed: 1.5ms preprocess, 97.0ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 448)\n",
      "Results saved to \u001b[1m/Users/gabrielvictorgomesferreira/runs/detect/predict4\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Load Model\n",
    "yolo11n = YOLO(model_loc)\n",
    "\n",
    "# Iterate through the images in the inference directory\n",
    "for image_file in os.listdir(inference_files_path):\n",
    "    if image_file.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
    "        input_image_path = os.path.join(inference_files_path, image_file)\n",
    "        prediction_file_path= os.path.join(prediction_files_path, image_file)\n",
    "        print(prediction_file_path)\n",
    "\n",
    "        # Run inference\n",
    "        results = yolo11n(input_image_path, save=True, save_dir=prediction_file_path, show=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "face_mask_detection_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
